{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as grb\n",
    "from gurobipy import GRB\n",
    "import scipy.sparse as spr\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "#from sympy import symbols, Rational\n",
    "from IPython.display import display, Math, Markdown\n",
    "import numpy.ma as ma\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\alpha_{ij}, \\gamma_{ij}\\in \\mathbb{R};$ $0=t^0<t^1<\\dots, t^K$ tax thresholds and $0 \\leq \\tau^0<\\tau^1<\\dots, \\tau^K$ progressive tax rates. Compute recursively $n^k$\n",
    "as $n^0 = 0, \\ n^k := n^{k-1} + (1-\\tau^k) (t^k -t^{k-1})$ and then $N^k := n^k - (1-\\tau^k) t^k .$\n",
    "\n",
    "\n",
    "\n",
    "We have \n",
    "$$ \\mathcal{U}_{ij}(v) = \\alpha_{ij} + \\min_{k \\in [0,K]} \\{N^k + (1-\\tau^k)(\\gamma_{ij} -v)\\}$$\n",
    "$$ \\mathcal{V}_{ij}(u) = \\gamma_{ij} + \\min_{k \\in [0,K]} \\left\\{ \\frac{N^k + \\alpha_{ij} -u}{1-\\tau^k}\\right\\}$$\n",
    "$$ D_{ij}(u,v) = \\max_{k \\in [0,K]} \\left\\{ \\frac{u-\\alpha_{ij} - N^k + (1-\\tau^k) (v_j - \\gamma_{ij})}{2-\\tau_k}\\right\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneToOneITU():\n",
    "    def __init__(self, n, m, parameters = (None,None) , lbs=(0, 0)):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.lb_U, self.lb_V = lbs\n",
    "     \n",
    "       \n",
    "        self.α_ij = parameters[0]\n",
    "        self.γ_ij = parameters[1]\n",
    "        self.t_k, self.τ_k = parameters[2]\n",
    "\n",
    "        self.n_k = np.zeros(self.t_k.size)\n",
    "        for m in range(1,self.t_k.size):\n",
    "            self.n_k[m] = self.n_k[m -1] + (1-self.τ_k[m-1])* (self.t_k[m] - self.t_k[m-1])\n",
    "        self.N_k = self.n_k - (1-self.τ_k) * self.t_k  \n",
    "     \n",
    "\n",
    "    def D_ij(self, u_i, v_j):\n",
    "        D = np.max( (u_i[:,None,None] - self.α_ij[:,:,None] - self.N_k[None,None,:]+  \n",
    "                     (1 - self.τ_k[None,None,:] )*(v_j[None,:,None] -self.γ_ij[:,:,None] ))/ \n",
    "                     (2 - self.τ_k[None,None,:]),      \n",
    "                     axis= 2)\n",
    "        return D\n",
    " \n",
    "    def get_U_ij(self, v_j, i_idx ,j_idx = None):\n",
    "        if j_idx is None:\n",
    "            return self.α_ij[i_idx] +   np.min(self.N_k[None,None,:] + (1- self.τ_k[None,None,:])  * ( self.γ_ij[i_idx,:,None] - v_j[None, :, None] ), axis= 2)\n",
    "        else:\n",
    "            return self.α_ij[i_idx,j_idx] +   np.min(self.N_k[None,None,:] + (1- self.τ_k[None,None,:])  * ( self.γ_ij[i_idx,j_idx,None] - v_j[None, :, None] ), axis= 2)\n",
    "\n",
    "    def get_V_ij(self, u_i, j_idx ,i_idx = None):\n",
    "        if i_idx is None:\n",
    "            return self.γ_ij[:,j_idx] + np.min ( (self.N_k[None,None,:] + self.α_ij[:,j_idx,None] - u_i[:,None,None])/(1-self.τ_k[None,None,:]) , axis = 2) \n",
    "        else:\n",
    "           \n",
    "            return self.γ_ij[i_idx,j_idx] + np.min ( (self.N_k[None,None,:] + self.α_ij[i_idx,j_idx,None] - u_i[:,None,None])/(1-self.τ_k[None,None,:]) , axis = 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_primal_feas(self, mu_ij):\n",
    "    print(f\"i: { np.all(np.sum(mu_ij,axis=1) <= 1)}, j:  {np.all(np.sum(mu_ij,axis=0) <= 1) }\")\n",
    "    print(f\"#matched: {int(np.sum(mu_ij))} over {np.minimum(self.n,self.m)}\")\n",
    "\n",
    "OneToOneITU.check_primal_feas = check_primal_feas\n",
    "\n",
    "def check_IR(self,mu_ij,U_i,V_j, output = False):\n",
    "    IR_i = np.sum((U_i - self.lb_U)* (1- np.sum(mu_ij,axis=1)))\n",
    "    IR_j = np.sum((V_j - self.lb_V) * (1 - np.sum(mu_ij,axis=0))) \n",
    "    print(f\"i: { IR_i}, j:  {IR_j }\")\n",
    "    if output is True:\n",
    "        IR_i = (U_i - self.lb_U)* (np.sum(mu_ij,axis=1) - 1) >= 0 \n",
    "        IR_j = (V_j - self.lb_V) * (np.sum(mu_ij,axis=0) - 1) >= 0\n",
    "        return IR_i, IR_j\n",
    "    \n",
    "OneToOneITU.check_IR = check_IR\n",
    "\n",
    "def check_CS(self,U_i,V_j, output = None):\n",
    "    CS = np.minimum(self.D_ij(U_i,V_j),0)\n",
    "    if output:\n",
    "        return CS, np.where(CS < 0 )\n",
    "    print(f\"min_ij D_ij : {(self.D_ij(U_i,V_j)).min()} \")\n",
    "    \n",
    "OneToOneITU.check_CS = check_CS \n",
    "\n",
    "def check_all(self,eq):\n",
    "    mu_ij, U_i, V_j = eq \n",
    "    print(\"FEAS\")\n",
    "    self.check_primal_feas(mu_ij)\n",
    "    print(\"________________\")\n",
    "    print(\"ε-CS\")\n",
    "    self.check_CS(U_i, V_j )\n",
    "    print(\"________________\")\n",
    "    print(\"IR\")\n",
    "    self.check_IR(mu_ij, U_i, V_j )\n",
    "\n",
    "OneToOneITU.check_all = check_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def forward_auction(self, data = None, tol_ε = None):\n",
    "    if data is None:\n",
    "        V_j = np.ones(self.m) * self.lb_V\n",
    "        mu_i = np.ones( self.n, dtype= int) * (self.m +1)\n",
    "    else:\n",
    "        mu_ij_01 = data[0]\n",
    "        V_j = data[1]\n",
    "        id_i, id_j = np.where(mu_ij_01 > 0)\n",
    "        mu_i = np.ones(self.n, dtype= int) * (self.m+1)\n",
    "        mu_i[id_i] = id_j\n",
    "\n",
    "    unassigned_i = np.where(mu_i == self.m + 1)[0] \n",
    "    n_unassigned_i = len(unassigned_i)\n",
    "    iter = 0\n",
    "\n",
    "    while n_unassigned_i > 0:\n",
    "        iter += 1\n",
    "        U_ij = self.get_U_ij( V_j, unassigned_i)\n",
    "        perm_unmatched = np.all(U_ij <= self.lb_U+tol_ε, axis = 1)#np.all(U_ij <= self.lb_U, axis = 1)\n",
    "        \n",
    "        if np.any(perm_unmatched):\n",
    "            mu_i[unassigned_i] += (self.m - mu_i[unassigned_i]) * perm_unmatched\n",
    "        else:\n",
    "            ### bidding phase\n",
    "            U_ij = np.concatenate((U_ij, self.lb_U * np.ones((n_unassigned_i,1))), axis = 1)\n",
    "            j_i = np.argmax(U_ij, axis= 1)\n",
    "            masked_U_ij = np.where(j_i[:,None] == np.arange(self.m+1)[None, :], -np.inf,U_ij)\n",
    "            w_i = np.max(masked_U_ij, axis=1)\n",
    "            j_i_unique = np.unique(j_i)\n",
    "            offers = np.where(j_i[:,None] == j_i_unique[None,:], \n",
    "                              self.get_V_ij(w_i - tol_ε,j_i_unique[None,:],unassigned_i[:,None]), \n",
    "                              np.nan)\n",
    "       \n",
    "            ### assignment phase\n",
    "            i_j_among_unass = np.nanargmax(offers, axis = 0)\n",
    "            i_j = unassigned_i[ i_j_among_unass]\n",
    "            best_offer_j = offers[i_j_among_unass, np.arange(len(j_i_unique))]\n",
    "\n",
    "            # modify solution\n",
    "            mu_i[  np.any( mu_i[:,None] == j_i_unique , axis = 1) ] = self.m +1\n",
    "            mu_i[i_j] = j_i_unique\n",
    "            V_j[j_i_unique] = best_offer_j #- V_j[j_i_unique] + tol_ε / self.A_ij[i_j,j_i_unique] #np.maximum(best_offer_j - V_j[j_i_unique], tol_ε/self.A_ij[i_j,j_i_unique])\n",
    "        \n",
    "        unassigned_i = np.where(mu_i == self.m + 1)[0]\n",
    "        n_unassigned_i = len(unassigned_i)\n",
    "        \n",
    "    print(f\"for: {iter}\")\n",
    "    matched_i =  mu_i < self.m\n",
    "    U_i = np.ones(self.n) * self.lb_U\n",
    "    U_i[matched_i] = self.get_U_ij(V_j, matched_i)[np.arange(matched_i.sum()), mu_i[matched_i]]\n",
    "    mu_ij_01 = mu_i[:,None] == np.arange(self.m +1)\n",
    "    \n",
    "    return mu_ij_01[:,:-1], U_i, V_j\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OneToOneITU.forward_auction = forward_auction\n",
    "def reverse_auction(self, data = None, tol_ε = None):\n",
    "    if data is None:\n",
    "        U_i = np.ones(self.n) * self.lb_U\n",
    "        mu_j = np.ones(self.m, dtype= int) * (self.n +1)\n",
    "    else:\n",
    "        mu_j_01 = data[0]\n",
    "        U_i = data[1]\n",
    "        id_i, id_j = np.where(mu_j_01 >0)\n",
    "        mu_j = np.ones(self.m, dtype= int) * (self.n+1)\n",
    "        mu_j[id_j] = id_i\n",
    "\n",
    "    unassigned_j = np.where(mu_j == self.n + 1)[0] \n",
    "    n_unassigned_j = len(unassigned_j)\n",
    "    iter = 0\n",
    "\n",
    "    while n_unassigned_j > 0:\n",
    "        iter += 1\n",
    "        V_ij = self.get_V_ij( U_i , unassigned_j)\n",
    "        perm_unmatched = np.all(V_ij <= self.lb_V+ tol_ε, axis = 0) \n",
    "        \n",
    "        if np.any(perm_unmatched):\n",
    "            mu_j[unassigned_j] += (self.n - mu_j[unassigned_j]) * perm_unmatched\n",
    "        \n",
    "        else:\n",
    "            ### bidding phase\n",
    "            V_ij = np.concatenate((V_ij, self.lb_V * np.ones((1,n_unassigned_j))), axis = 0)\n",
    "            i_j = np.argmax(V_ij, axis= 0)\n",
    "            masked_V_ij = np.where( np.arange(self.n+1)[:, None] == i_j[None,:] , -np.inf,V_ij)\n",
    "            β_j = np.max(masked_V_ij, axis=0)\n",
    "            i_j_unique = np.unique(i_j)\n",
    "            offers = np.where(i_j_unique[:,None] == i_j[None,:], \n",
    "                              self.get_U_ij(β_j - tol_ε,i_j_unique[:,None] ,unassigned_j[None,:]), \n",
    "                              np.nan)\n",
    "\n",
    "            ### assignment phase\n",
    "            j_i_among_unass = np.nanargmax(offers, axis = 1)\n",
    "            j_i = unassigned_j[j_i_among_unass]\n",
    "            best_offer_i = offers[np.arange(len(i_j_unique)),j_i_among_unass]\n",
    "            # modify solution\n",
    "            mu_j[ np.any( mu_j[:,None] == i_j_unique , axis = 1) ] = self.n +1\n",
    "            mu_j[j_i] = i_j_unique\n",
    "            U_i[i_j_unique] = best_offer_i\n",
    "                                        \n",
    "        unassigned_j = np.where(mu_j == self.n + 1)[0]\n",
    "        n_unassigned_j = len(unassigned_j)\n",
    "        \n",
    "    print(f\"rev: {iter}\") \n",
    "    matched_j =  mu_j < self.n\n",
    "    V_j = np.ones(self.m) * self.lb_V\n",
    "    V_j[mu_j < self.n] = self.get_V_ij(U_i, matched_j )[mu_j[matched_j],np.arange(matched_j.sum()) ]\n",
    "    mu_j_01 = np.arange(self.n +1)[:,None] == mu_j[None,:]\n",
    "\n",
    "    return mu_j_01[:-1,:], U_i, V_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OneToOneITU.reverse_auction = reverse_auction\n",
    "def drop_for_scaling(self, mu_ij_01, U_i,V_j, tol_ε, side = 1):\n",
    "    if side == 1:\n",
    "        violations_j = np.any( V_j[None,:] + tol_ε <  self.get_V_ij(U_i  ,np.arange(self.m)), axis=  0)\n",
    "        #violations_j = np.any( V_j[None,:] <  self.get_V_ij(U_i + tol_ε ,np.arange(self.m)), axis=  0)\n",
    "        # print(violations_j.sum())\n",
    "        mu_ij_01[:,violations_j] = 0\n",
    "\n",
    "        print(f\"dropped: {violations_j.sum()}\")\n",
    "        # violations_i = np.any( U_i[:,None]+ tol_ε <  self.get_U_ij(V_j,np.arange(self.n)), axis=  1)\n",
    "        # print(violations_i.sum())\n",
    "        # mu_ij_01[violations_i,:] = 0\n",
    "\n",
    "      \n",
    "    else:\n",
    "        violations_i = np.any( U_i[:,None] + tol_ε <  self.get_U_ij(V_j  ,np.arange(self.n)), axis=  1)\n",
    "   \n",
    "        mu_ij_01[violations_i,:] = 0\n",
    "\n",
    "        print(f\"dropped: {violations_i.sum()}\")\n",
    "        # violations_i = np.any( U_i[:,None]+ tol_ε <  self.get_U_ij(V_j,np.arange(self.n)), axis=  1)\n",
    "        # print(violations_i.sum())\n",
    "        # mu_ij_01[violations_i,:] = 0\n",
    "\n",
    "    return mu_ij_01, U_i,V_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OneToOneITU.drop_for_scaling = drop_for_scaling\n",
    "def forward_backward_scaling(self, tol_ε ,tol_ε_obj, scaling_factor):\n",
    "    mu_ij_01, u_i, v_j = self.forward_auction(tol_ε = tol_ε)\n",
    "\n",
    "    while tol_ε > tol_ε_obj:\n",
    "        tol_ε *=  scaling_factor\n",
    "        # print(\"####\")\n",
    "        # print( tol_ε)\n",
    "        print(\"#######\")\n",
    "        mu_ij_01, u_i, v_j = self.drop_for_scaling(mu_ij_01, u_i, v_j , tol_ε)\n",
    "        mu_ij_01, u_i, v_j = self.reverse_auction((mu_ij_01, u_i), tol_ε= tol_ε)\n",
    "        # tol_ε *=  scaling_factor\n",
    "        #mu_ij_01, u_i, v_j = self.drop_for_scaling(mu_ij_01, u_i, v_j , tol_ε, side = 0)\n",
    "        mu_ij_01, u_i, v_j = self.forward_auction((mu_ij_01, v_j ), tol_ε = tol_ε)\n",
    "        self.check_CS(u_i,v_j)\n",
    "        # print(np.all(self.check_CS(u_i,v_j,True)[0]>= - tol_ε_obj))\n",
    "\n",
    "        if np.all(self.check_CS(u_i,v_j,True)[0]>= - tol_ε_obj):\n",
    "             return mu_ij_01, u_i, v_j\n",
    "\n",
    "    return mu_ij_01, u_i, v_j\n",
    "OneToOneITU.forward_backward_scaling =forward_backward_scaling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_i =  100\n",
    "m_j  = 120\n",
    "np.random.seed(123)\n",
    "α_ij = np.zeros([n_i,m_j]) #np.random.choice([.25,.5,1,2,4], size= [n_i,m_j])\n",
    "γ_ij= np.random.randint(0,5, size= [ n_i,1]) * np.random.randint(0,5, size= [ 1,m_j])  #np.random.randint(1,10000, size= [ n_i,1]) * np.random.randint(1,20, size= [ 1,m_j])\n",
    "t_k = np.array([0, 9.701, 39.476, 84.201, 160.726, 204.101, 510.300])/100\n",
    "tau_k =  np.array([.1,.12,   .22,    .24,    .32,     .35,     .37    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.09701, 0.39476, 0.84201, 1.60726, 2.04101, 5.103  ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mkt = OneToOneITU(  n_i,m_j,parameters=(α_ij,γ_ij,(t_k,tau_k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9000.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_mkt.get_U_ij(np.ones(1)* 10000,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 120)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(example_mkt.get_V_ij(np.ones(n_i),np.ones(m_j, dtype=bool)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run /Users/enzo-macmini/auction_alg_ITU/for_rev_scaling_ALGs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(example_mkt.get_V_ij(u_i_noscaling,np.arange(example_mkt.m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eq_noscaling = mu_ij_01_noscaling, u_i_noscaling, v_j_noscaling = example_mkt.forward_auction(tol_ε= .1)\n",
    "# # print(np.all( u_i_noscaling[:,None]+ 1>=  example_mkt.get_U_ij(v_j_noscaling,np.arange(example_mkt.n)), axis= 1 ))\n",
    "# print(np.min(u_i_noscaling[:,None] -  example_mkt.get_U_ij(v_j_noscaling,np.arange(example_mkt.n))))\n",
    "# print(np.min(v_j_noscaling[None,:] -  example_mkt.get_V_ij(u_i_noscaling,np.arange(example_mkt.m))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for: 1\n",
      "#######\n",
      "dropped: 0\n",
      "rev: 1\n",
      "for: 1\n",
      "min_ij D_ij : -6.398851226993865 \n",
      "#######\n",
      "dropped: 0\n",
      "rev: 1\n",
      "for: 1\n",
      "min_ij D_ij : -6.398851226993865 \n",
      "#######\n",
      "dropped: 0\n",
      "rev: 1\n",
      "for: 1\n",
      "min_ij D_ij : -6.398851226993865 \n",
      "#######\n",
      "dropped: 0\n",
      "rev: 1\n",
      "for: 1\n",
      "min_ij D_ij : -6.398851226993865 \n",
      "#######\n",
      "dropped: 0\n",
      "rev: 1\n",
      "for: 1\n",
      "min_ij D_ij : -6.398851226993865 \n",
      "#######\n",
      "dropped: 22\n",
      "rev: 20\n",
      "for: 1\n",
      "min_ij D_ij : -6.253912576687116 \n",
      "#######\n",
      "dropped: 50\n",
      "rev: 36\n",
      "for: 28\n",
      "min_ij D_ij : -4.792944785276075 \n",
      "#######\n",
      "dropped: 53\n",
      "rev: 63\n",
      "for: 36\n",
      "min_ij D_ij : -2.396472392638037 \n",
      "#######\n",
      "dropped: 50\n",
      "rev: 77\n",
      "for: 53\n",
      "min_ij D_ij : -1.1982361963190185 \n",
      "#######\n",
      "dropped: 86\n",
      "rev: 105\n",
      "for: 84\n",
      "min_ij D_ij : -0.5991180981595087 \n",
      "#######\n",
      "dropped: 74\n",
      "rev: 155\n",
      "for: 54\n",
      "min_ij D_ij : -0.2995590490797546 \n",
      "#######\n",
      "dropped: 78\n",
      "rev: 72\n",
      "for: 47\n",
      "min_ij D_ij : -0.1497795245398773 \n",
      "#######\n",
      "dropped: 79\n",
      "rev: 110\n",
      "for: 60\n",
      "min_ij D_ij : -0.07488976226993865 \n",
      "#######\n",
      "dropped: 87\n",
      "rev: 97\n",
      "for: 49\n",
      "min_ij D_ij : -0.03744488113496933 \n",
      "#######\n",
      "dropped: 75\n",
      "rev: 116\n",
      "for: 60\n",
      "min_ij D_ij : -0.018722440567484663 \n",
      "#######\n",
      "dropped: 88\n",
      "rev: 98\n",
      "for: 59\n",
      "min_ij D_ij : -0.009361220283742332 \n",
      "#######\n",
      "dropped: 84\n",
      "rev: 116\n",
      "for: 58\n",
      "min_ij D_ij : -0.004680610141871166 \n",
      "#######\n",
      "dropped: 91\n",
      "rev: 96\n",
      "for: 102\n",
      "min_ij D_ij : -0.002340305070935583 \n",
      "#######\n",
      "dropped: 60\n",
      "rev: 135\n",
      "for: 57\n",
      "min_ij D_ij : -0.001170152535468064 \n",
      "#######\n",
      "dropped: 86\n",
      "rev: 92\n",
      "for: 60\n",
      "min_ij D_ij : -0.0005850762677338957 \n",
      "#######\n",
      "dropped: 85\n",
      "rev: 117\n",
      "for: 57\n",
      "min_ij D_ij : -0.00029253813386694786 \n",
      "#######\n",
      "dropped: 90\n",
      "rev: 83\n",
      "for: 56\n",
      "min_ij D_ij : -0.00014626906693347393 \n",
      "#######\n",
      "dropped: 86\n",
      "rev: 113\n",
      "for: 56\n",
      "min_ij D_ij : -7.313453346646452e-05 \n",
      "#######\n",
      "dropped: 86\n",
      "rev: 96\n",
      "for: 77\n",
      "min_ij D_ij : -3.6567266733913376e-05 \n",
      "#######\n",
      "dropped: 86\n",
      "rev: 106\n",
      "for: 77\n",
      "min_ij D_ij : -1.8283633366956688e-05 \n",
      "#######\n",
      "dropped: 92\n",
      "rev: 100\n",
      "for: 71\n",
      "min_ij D_ij : -9.141816683614569e-06 \n",
      "#######\n",
      "dropped: 75\n",
      "rev: 129\n",
      "for: 78\n",
      "min_ij D_ij : -4.57090834167106e-06 \n",
      "#######\n",
      "dropped: 91\n",
      "rev: 82\n",
      "for: 58\n",
      "min_ij D_ij : -2.28545417083553e-06 \n",
      "#######\n",
      "dropped: 78\n",
      "rev: 124\n",
      "for: 55\n",
      "min_ij D_ij : -1.142727085417765e-06 \n",
      "#######\n",
      "dropped: 78\n",
      "rev: 93\n",
      "for: 60\n",
      "min_ij D_ij : -5.713635427088825e-07 \n",
      "#######\n",
      "dropped: 88\n",
      "rev: 116\n",
      "for: 51\n",
      "min_ij D_ij : -2.856817710819939e-07 \n",
      "#######\n",
      "dropped: 88\n",
      "rev: 94\n",
      "for: 55\n",
      "min_ij D_ij : -1.4284088567722064e-07 \n",
      "#######\n",
      "dropped: 79\n",
      "rev: 116\n",
      "for: 61\n",
      "min_ij D_ij : -7.142044311105769e-08 \n",
      "#######\n",
      "dropped: 82\n",
      "rev: 98\n",
      "for: 58\n",
      "min_ij D_ij : -3.571022141930516e-08 \n",
      "#######\n",
      "dropped: 76\n",
      "rev: 114\n",
      "for: 80\n",
      "min_ij D_ij : -1.785511070965258e-08 \n",
      "#######\n",
      "dropped: 89\n",
      "rev: 98\n",
      "for: 54\n",
      "min_ij D_ij : -8.92755535482629e-09 \n",
      "#######\n",
      "dropped: 72\n",
      "rev: 115\n",
      "for: 77\n",
      "min_ij D_ij : -4.463777949860513e-09 \n",
      "#######\n",
      "dropped: 86\n",
      "rev: 107\n",
      "for: 72\n",
      "min_ij D_ij : -2.2318888387065725e-09 \n",
      "#######\n",
      "dropped: 76\n",
      "rev: 120\n",
      "for: 49\n",
      "min_ij D_ij : -1.1159446918006543e-09 \n",
      "#######\n",
      "dropped: 82\n",
      "rev: 90\n",
      "for: 56\n",
      "min_ij D_ij : -5.579719372292751e-10 \n",
      "#######\n",
      "dropped: 85\n",
      "rev: 135\n",
      "for: 57\n",
      "min_ij D_ij : -2.7898610483832156e-10 \n",
      "#######\n",
      "dropped: 71\n",
      "rev: 110\n",
      "for: 84\n",
      "min_ij D_ij : -1.3949305241916078e-10 \n",
      "#######\n",
      "dropped: 75\n",
      "rev: 121\n",
      "for: 56\n",
      "min_ij D_ij : -6.974625376221238e-11 \n",
      "#######\n",
      "dropped: 88\n",
      "rev: 94\n",
      "for: 50\n",
      "min_ij D_ij : -3.4873263104790195e-11 \n",
      "#######\n",
      "dropped: 75\n",
      "rev: 122\n",
      "for: 1\n",
      "min_ij D_ij : -1.227301089040173e-11 \n",
      "#######\n",
      "dropped: 45\n",
      "rev: 55\n",
      "for: 79\n",
      "min_ij D_ij : -8.718315776197549e-12 \n",
      "#######\n",
      "dropped: 53\n",
      "rev: 131\n",
      "for: 1\n",
      "min_ij D_ij : -3.0683158034541047e-12 \n",
      "#######\n",
      "dropped: 54\n",
      "rev: 59\n",
      "for: 73\n",
      "min_ij D_ij : -2.1798513914173935e-12 \n",
      "#######\n",
      "dropped: 65\n",
      "rev: 139\n",
      "for: 1\n",
      "min_ij D_ij : -7.6712626150378e-13 \n",
      "#######\n",
      "dropped: 62\n",
      "rev: 52\n",
      "for: 70\n",
      "min_ij D_ij : -5.382899513334093e-13 \n",
      "#######\n",
      "dropped: 75\n",
      "rev: 107\n",
      "for: 1\n",
      "min_ij D_ij : -1.9176579516252704e-13 \n",
      "#######\n",
      "dropped: 61\n",
      "rev: 56\n",
      "for: 64\n",
      "min_ij D_ij : -1.3567878926707434e-13 \n",
      "#######\n",
      "dropped: 49\n",
      "rev: 106\n",
      "for: 1\n",
      "min_ij D_ij : -4.794144879063176e-14 \n"
     ]
    }
   ],
   "source": [
    "eq_scaling = mu_ij_01_scaling, u_i_scaling, v_j_scaling = example_mkt.forward_backward_scaling(1000,1e-13,1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_ij D_ij : -4.794144879063176e-14 \n"
     ]
    }
   ],
   "source": [
    "example_mkt.check_CS(u_i_scaling, v_j_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEAS\n",
      "i: True, j:  True\n",
      "#matched: 84 over 100\n",
      "________________\n",
      "ε-CS\n",
      "min_ij D_ij : -4.794144879063176e-14 \n",
      "________________\n",
      "IR\n",
      "i: 0.0, j:  0.0\n"
     ]
    }
   ],
   "source": [
    "example_mkt.check_all((mu_ij_01_scaling, u_i_scaling, v_j_scaling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.43769498715119e-14\n",
      "-1.1102230246251565e-13\n"
     ]
    }
   ],
   "source": [
    "print(np.min(u_i_scaling[:,None] -  example_mkt.get_U_ij(v_j_scaling,np.arange(example_mkt.n))))\n",
    "print(np.min(v_j_scaling[None,:] -  example_mkt.get_V_ij(u_i_scaling,np.arange(example_mkt.m))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.000000000000064"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_j_scaling.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.880952380952392"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( (example_mkt.γ_ij - v_j_scaling[None,:])[mu_ij_01_scaling>0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8327265470000045"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_i_scaling.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
